{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do all the numbers tell you?\n",
    "89/90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorAssembler}\n",
    "import org.apache.spark.{SparkConf, SparkContext}\n",
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.classification.RandomForestClassifier\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.rdd.RDD\n",
    "import scala.collection.mutable.ListBuffer\n",
    "import org.apache.spark.ml.classification.LinearSVC\n",
    "import org.apache.spark.ml.classification.NaiveBayes\n",
    "import org.apache.spark.ml.classification.GBTClassifier\n",
    "import org.apache.spark.ml.classification.DecisionTreeClassificationModel\n",
    "import org.apache.spark.ml.classification.DecisionTreeClassifier\n",
    "import org.apache.spark.ml.regression.DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+-------+-----+------+--------+------+------+------+------+\n",
      "|_c0|outcome|age|yronset|premi|smstat|diabetes|highbp|hichol|angina|stroke|\n",
      "+---+-------+---+-------+-----+------+--------+------+------+------+------+\n",
      "|  1|   live| 63|     85|    n|     x|       n|     y|     y|     n|     n|\n",
      "|  6|   live| 55|     85|    n|     c|       n|     y|     y|     n|     n|\n",
      "|  8|   live| 68|     85|    y|    nk|      nk|     y|    nk|     y|     n|\n",
      "| 10|   live| 64|     85|    n|     x|       n|     y|     n|     y|     n|\n",
      "| 11|   dead| 67|     85|    n|    nk|      nk|    nk|    nk|    nk|    nk|\n",
      "| 15|   live| 66|     85|    n|     x|      nk|    nk|    nk|    nk|    nk|\n",
      "| 21|   live| 63|     85|    n|     n|       n|     y|     n|     n|     n|\n",
      "| 22|   dead| 68|     85|    y|     n|       n|     y|     y|     y|     y|\n",
      "| 23|   dead| 46|     85|    n|     c|       n|     y|    nk|    nk|     n|\n",
      "| 28|   dead| 66|     85|    y|     c|       n|     y|     n|     n|     y|\n",
      "| 36|   dead| 59|     85|    n|     c|       n|     y|     n|     n|     n|\n",
      "| 40|   live| 63|     85|    n|     n|       n|     y|     y|     n|     n|\n",
      "| 41|   live| 55|     85|    n|     c|       n|     n|     y|     n|     y|\n",
      "| 43|   live| 56|     85|    n|     n|       n|     y|     y|     y|     n|\n",
      "| 44|   dead| 67|     85|    n|     x|       n|     n|     n|     y|     n|\n",
      "| 50|   live| 64|     85|    n|     n|       n|     n|     n|     y|     n|\n",
      "| 52|   dead| 60|     85|    n|     n|       n|     n|     n|     n|     n|\n",
      "| 53|   dead| 61|     85|   nk|     n|       y|     y|     n|     y|     y|\n",
      "| 65|   live| 69|     85|    y|     x|       n|     y|     n|     y|     n|\n",
      "| 68|   live| 59|     85|    n|     c|       n|     y|     n|     n|     n|\n",
      "+---+-------+---+-------+-----+------+--------+------+------+------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- outcome: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- yronset: integer (nullable = true)\n",
      " |-- premi: string (nullable = true)\n",
      " |-- smstat: string (nullable = true)\n",
      " |-- diabetes: string (nullable = true)\n",
      " |-- highbp: string (nullable = true)\n",
      " |-- hichol: string (nullable = true)\n",
      " |-- angina: string (nullable = true)\n",
      " |-- stroke: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val mifemdata = spark.read.format(\"csv\").option(\"header\",true).option(\"inferschema\",true).option(\"sep\",\",\").load(\"mifem.csv\")\n",
    "val mifemCleandata = mifemdata.na.drop\n",
    "mifemCleandata.show()\n",
    "mifemCleandata.printSchema()\n",
    "val mifemDataset = mifemCleandata.select(\"outcome\",\"age\",\"yronset\",\"premi\",\"smstat\",\"diabetes\",\"highbp\",\"hichol\",\"angina\",\"stroke\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val categoryColNames = List(\"premi\",\"smstat\",\"diabetes\",\"highbp\",\"hichol\",\"angina\",\"stroke\")\n",
    "    val stringIndexersFeatures = categoryColNames.map { columnName =>\n",
    "      new StringIndexer()\n",
    "        .setInputCol(columnName)\n",
    "        .setOutputCol(columnName + \"Indexed\")\n",
    "        .fit(mifemDataset)\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListBuffer(premiIndexed, smstatIndexed, diabetesIndexed, highbpIndexed, hicholIndexed, anginaIndexed, strokeIndexed, age, yronset)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val outcomeIndexer = new StringIndexer().setInputCol(\"outcome\").setOutputCol(\"outcomeIndexed\").fit(mifemDataset)\n",
    "var catColNameIndexed = new ListBuffer[String]()\n",
    "catColNameIndexed = categoryColNames.map(_ + \"Indexed\").to[ListBuffer]\n",
    "catColNameIndexed += \"age\"\n",
    "catColNameIndexed += \"yronset\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+--------------------+\n",
      "|outcome|outcomeIndexed|            Features|\n",
      "+-------+--------------+--------------------+\n",
      "|   live|           0.0|(9,[1,4,7,8],[2.0...|\n",
      "|   live|           0.0|(9,[1,4,7,8],[1.0...|\n",
      "|   live|           0.0|[1.0,3.0,2.0,0.0,...|\n",
      "|   live|           0.0|(9,[1,5,7,8],[2.0...|\n",
      "|   dead|           1.0|[0.0,3.0,2.0,2.0,...|\n",
      "|   live|           0.0|[0.0,2.0,2.0,2.0,...|\n",
      "|   live|           0.0|(9,[7,8],[63.0,85...|\n",
      "|   dead|           1.0|[1.0,0.0,0.0,0.0,...|\n",
      "|   dead|           1.0|[0.0,1.0,0.0,0.0,...|\n",
      "|   dead|           1.0|[1.0,1.0,0.0,0.0,...|\n",
      "|   dead|           1.0|(9,[1,7,8],[1.0,5...|\n",
      "|   live|           0.0|(9,[4,7,8],[1.0,6...|\n",
      "|   live|           0.0|[0.0,1.0,0.0,1.0,...|\n",
      "|   live|           0.0|(9,[4,5,7,8],[1.0...|\n",
      "|   dead|           1.0|[0.0,2.0,0.0,1.0,...|\n",
      "|   live|           0.0|(9,[3,5,7,8],[1.0...|\n",
      "|   dead|           1.0|(9,[3,7,8],[1.0,6...|\n",
      "|   dead|           1.0|[2.0,0.0,1.0,0.0,...|\n",
      "|   live|           0.0|[1.0,2.0,0.0,0.0,...|\n",
      "|   live|           0.0|(9,[1,7,8],[1.0,5...|\n",
      "+-------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val assembler = new VectorAssembler().setInputCols(Array(catColNameIndexed: _*)).setOutputCol(\"Features\")\n",
    "val pipelineMifem = new Pipeline().setStages(Array(stringIndexersFeatures: _*)++ Array(outcomeIndexer,assembler))\n",
    "val indexedData = pipelineMifem.fit(mifemDataset).transform(mifemDataset)\n",
    "val outcomeFeatureData = indexedData.select(\"outcome\",\"outcomeIndexed\",\"Features\")\n",
    "val labelConverter = new IndexToString().setInputCol(\"prediction\").setOutputCol(\"predictedLabel\").setLabels(outcomeIndexer.labels)\n",
    "outcomeFeatureData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age : 0.12576387152792115\n",
      "yronset : -0.08693864419542775\n",
      "premiIndexed : 0.24278346151896188\n",
      "smstatIndexed : 0.1809504994879566\n",
      "diabetesIndexed : 0.3129038101726261\n",
      "highbpIndexed : 0.22478366832372196\n",
      "hicholIndexed : 0.16789778400628724\n",
      "anginaIndexe : 0.32674068022275105\n",
      "strokeIndexed : 0.36918698354044277\n"
     ]
    }
   ],
   "source": [
    " val corr1 = indexedData.stat.corr(\"outcomeIndexed\",\"age\")\n",
    "    var correlation = \"age : \" + corr1 + \"\\n\"\n",
    "    val corr2 = indexedData.stat.corr(\"outcomeIndexed\",\"yronset\")\n",
    "    correlation += \"yronset : \" + corr2 + \"\\n\"\n",
    "    val corr3 = indexedData.stat.corr(\"outcomeIndexed\",\"premiIndexed\")\n",
    "    correlation += \"premiIndexed : \" + corr3 + \"\\n\"\n",
    "    val corr4 = indexedData.stat.corr(\"outcomeIndexed\",\"smstatIndexed\")\n",
    "    correlation += \"smstatIndexed : \" + corr4 + \"\\n\"\n",
    "    val corr5 = indexedData.stat.corr(\"outcomeIndexed\",\"diabetesIndexed\")\n",
    "    correlation += \"diabetesIndexed : \" + corr5 + \"\\n\"\n",
    "    val corr6 = indexedData.stat.corr(\"outcomeIndexed\",\"highbpIndexed\")\n",
    "    correlation += \"highbpIndexed : \" + corr6 + \"\\n\"\n",
    "    val corr7 = indexedData.stat.corr(\"outcomeIndexed\",\"hicholIndexed\")\n",
    "    correlation += \"hicholIndexed : \" + corr7 + \"\\n\"\n",
    "    val corr8 = indexedData.stat.corr(\"outcomeIndexed\",\"anginaIndexed\")\n",
    "    correlation += \"anginaIndexe : \" + corr8 + \"\\n\"\n",
    "    val corr9 = indexedData.stat.corr(\"outcomeIndexed\",\"strokeIndexed\")\n",
    "    correlation += \"strokeIndexed : \" + corr9 + \"\\n\"\n",
    "\n",
    "    print(correlation)  \n",
    "    val printing = sc.parallelize(Seq(correlation))\n",
    "    printing.saveAsTextFile(\"correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val randomForestModel = new RandomForestClassifier().setLabelCol(\"outcomeIndexed\").setFeaturesCol(\"Features\")\n",
    "val logisticRegressionModel = new LogisticRegression().setLabelCol(\"outcomeIndexed\").setFeaturesCol(\"Features\")\n",
    "val linearSVMModel = new LinearSVC().setMaxIter(10).setRegParam(0.1).setLabelCol(\"outcomeIndexed\").setFeaturesCol(\"Features\")\n",
    "val NaiveBayesModel = new NaiveBayes().setLabelCol(\"outcomeIndexed\").setFeaturesCol(\"Features\")\n",
    "val gbtModel = new GBTClassifier().setMaxIter(10).setLabelCol(\"outcomeIndexed\").setFeaturesCol(\"Features\")\n",
    "val decisiontreeModel = new DecisionTreeClassifier().setLabelCol(\"outcomeIndexed\").setFeaturesCol(\"Features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val pipelinerandomForest = new Pipeline().setStages(Array(randomForestModel,labelConverter))\n",
    "val pipelinelogisticRegression = new Pipeline().setStages(Array(logisticRegressionModel,labelConverter))\n",
    "val pipelinelinearSVM = new Pipeline().setStages(Array(linearSVMModel,labelConverter))\n",
    "val pipelineNaiveBayes = new Pipeline().setStages(Array(NaiveBayesModel,labelConverter))\n",
    "val pipelineGBT = new Pipeline().setStages(Array(gbtModel,labelConverter))\n",
    "val pipelinedecisionTree = new Pipeline().setStages(Array(decisiontreeModel,labelConverter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val Array(trainingData, testData) = outcomeFeatureData.randomSplit(Array(0.7, 0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " FUNCTIONS CORRECT AND WRONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correctPredictions(predictions: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] ): DataFrame = {\n",
    "val correctPredictions = predictions.where(expr(\"outcome == predictedLabel\"))\n",
    "val countCorrectPredictions = correctPredictions.groupBy(\"outcome\").agg(count(\"outcome\").alias(\"Correct\"))\n",
    "countCorrectPredictions.show()\n",
    "countCorrectPredictions.toDF\n",
    "}\n",
    "\n",
    "def wrongPredictions(predictions: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]): DataFrame = {\n",
    "val wrongPredictions = predictions.where(expr(\"outcome != predictedLabel\"))\n",
    "val countErrors = wrongPredictions.groupBy(\"outcome\").agg(count(\"outcome\").alias(\"Error\"))\n",
    "countErrors.toDF\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def accuracy(correctPredictions:DataFrame ,wrongPredictions:DataFrame,testData : DataFrame):(Double,String)=\n",
    "  {\n",
    "    val totalRecords=testData.count()\n",
    "    val trueNegative = correctPredictions.where(col(\"outcome\") ===  \"live\").select(\"Correct\")\n",
    "    var tn: Long = 0\n",
    "    if(trueNegative.count() == 0 ){\n",
    "      tn = 0\n",
    "    } else\n",
    "    {\n",
    "      tn = trueNegative.head().getLong(0)\n",
    "    }\n",
    "    var conf = \"True Negative : \" + tn + \"\\n\"\n",
    "    val truePositive = correctPredictions.where(col(\"outcome\") ===  \"dead\").select(\"Correct\")\n",
    "    var tp: Long = 0\n",
    "    if(truePositive.count() == 0 ){\n",
    "      tp = 0\n",
    "    } else {\n",
    "      tp = truePositive.head().getLong(0)\n",
    "    }\n",
    "    conf += \"True Positive : \" + tp + \"\\n\"\n",
    "\n",
    "    val falseNegative = wrongPredictions.where(col(\"outcome\") ===  \"dead\").select(\"Error\")\n",
    "    var fn: Long = 0\n",
    "    if(falseNegative.count() == 0 ){\n",
    "      fn = 0\n",
    "    } else\n",
    "    {\n",
    "      fn = falseNegative.head().getLong(0)\n",
    "    }\n",
    "    conf += \"False Negative : \" + fn + \"\\n\"\n",
    "    val falsePositive = wrongPredictions.where(col(\"outcome\") ===  \"live\").select(\"Error\")\n",
    "    var fp: Long = 0\n",
    "    if(falsePositive.count() == 0 ){\n",
    "      tp = 0\n",
    "    } else {\n",
    "      fp = falsePositive.head().getLong(0)\n",
    "    }\n",
    "    conf += \"False Positive : \" + fp+ \"\\n\"\n",
    "\n",
    "    val accuracy = (tp.toDouble + tn.toDouble)/totalRecords\n",
    "    (accuracy,conf)\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|outcome|Correct|\n",
      "+-------+-------+\n",
      "|   live|    293|\n",
      "|   dead|     28|\n",
      "+-------+-------+\n",
      "\n",
      "+-------+-----+\n",
      "|outcome|Error|\n",
      "+-------+-----+\n",
      "|   live|    4|\n",
      "|   dead|   81|\n",
      "+-------+-----+\n",
      "\n",
      "0.7906403940886699"
     ]
    }
   ],
   "source": [
    "val randomForest = pipelinerandomForest.fit(trainingData)\n",
    "randomForest.save(\"RandomForesModel\")\n",
    "val predictionsrandomForest = randomForest.transform(testData)\n",
    "var randomForestCorrect=correctPredictions(predictionsrandomForest)\n",
    "var randomForestWrong=wrongPredictions(predictionsrandomForest)\n",
    "randomForestWrong.show()\n",
    "val (randomAccuracy,matrixRandom) = accuracy(randomForestCorrect,randomForestWrong,testData)\n",
    "var accuracyString = \"RandomForest : \" + randomAccuracy + \"\\n\"\n",
    "var confRandom = sc.parallelize(Seq(matrixRandom))\n",
    "confRandom.saveAsTextFile(\"RandomForestConfusion\")\n",
    "print(randomAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|outcome|Correct|\n",
      "+-------+-------+\n",
      "|   live|    290|\n",
      "|   dead|     28|\n",
      "+-------+-------+\n",
      "\n",
      "+-------+-----+\n",
      "|outcome|Error|\n",
      "+-------+-----+\n",
      "|   live|    7|\n",
      "|   dead|   81|\n",
      "+-------+-----+\n",
      "\n",
      "0.7832512315270936"
     ]
    }
   ],
   "source": [
    "val logisticModel = pipelinelogisticRegression.fit(trainingData)\n",
    "logisticModel.save(\"logisticRegressionModel\")\n",
    "val predictionsLogistic = logisticModel.transform(testData)\n",
    "var logisticCorrect=correctPredictions(predictionsLogistic)\n",
    "var logisticWrong=wrongPredictions(predictionsLogistic)\n",
    "logisticWrong.show()\n",
    "val (logisticAccuracy,matrixLogistic)= accuracy(logisticCorrect,logisticWrong,testData)\n",
    "accuracyString += \"logisticRegression : \" + logisticAccuracy + \"\\n\"\n",
    "var confMatrixLogistic = sc.parallelize(Seq(matrixLogistic))\n",
    "confMatrixLogistic.saveAsTextFile(\"LogisticConfusion\")\n",
    "print(logisticAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LINEAR SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|outcome|Correct|\n",
      "+-------+-------+\n",
      "|   live|    297|\n",
      "+-------+-------+\n",
      "\n",
      "+-------+-----+\n",
      "|outcome|Error|\n",
      "+-------+-----+\n",
      "|   dead|  109|\n",
      "+-------+-----+\n",
      "\n",
      "0.7315270935960592"
     ]
    }
   ],
   "source": [
    "val linearSVM = pipelinelinearSVM.fit(trainingData)\n",
    "linearSVM.save(\"LinearSVMModel\")\n",
    "val predictionslinearSVM = linearSVM.transform(testData)\n",
    "var linearSVMCorrect=correctPredictions(predictionslinearSVM)\n",
    "var linearSVMWrong=wrongPredictions(predictionslinearSVM)\n",
    "linearSVMWrong.show()\n",
    "val (linearSVMAccuracy,matrixLinearSVM) = accuracy(linearSVMCorrect,linearSVMWrong,testData)\n",
    "accuracyString += \"linearSVM : \" + linearSVMAccuracy + \"\\n\"\n",
    "var confMatrixLinearSVM = sc.parallelize(Seq(matrixLinearSVM))\n",
    "confMatrixLinearSVM.saveAsTextFile(\"LinearSVMConfusion\")\n",
    "print(linearSVMAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaiveBayesModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|outcome|Correct|\n",
      "+-------+-------+\n",
      "|   live|    278|\n",
      "|   dead|     36|\n",
      "+-------+-------+\n",
      "\n",
      "+-------+-----+\n",
      "|outcome|Error|\n",
      "+-------+-----+\n",
      "|   live|   19|\n",
      "|   dead|   73|\n",
      "+-------+-----+\n",
      "\n",
      "0.7733990147783252"
     ]
    }
   ],
   "source": [
    "val naiveBayes = pipelineNaiveBayes.fit(trainingData)\n",
    "naiveBayes.save(\"NaiveBayesModel\")\n",
    "val predictionsNaiveBayes = naiveBayes.transform(testData)\n",
    "var naiveBayesCorrect=correctPredictions(predictionsNaiveBayes)\n",
    "var naiveBayesWrong=wrongPredictions(predictionsNaiveBayes)\n",
    "naiveBayesWrong.show()\n",
    "val (naiveBayesAccuracy,matrixNaiveBayes) = accuracy(naiveBayesCorrect,naiveBayesWrong,testData)\n",
    "accuracyString += \"NaiveBayes: \" + naiveBayesAccuracy + \"\\n\"\n",
    "var confMatrixNaiveBayes = sc.parallelize(Seq(matrixNaiveBayes))\n",
    "confMatrixNaiveBayes.saveAsTextFile(\"NaiveBayesConfusion\")\n",
    "print(naiveBayesAccuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gbtModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|outcome|Correct|\n",
      "+-------+-------+\n",
      "|   live|    282|\n",
      "|   dead|     32|\n",
      "+-------+-------+\n",
      "\n",
      "+-------+-----+\n",
      "|outcome|Error|\n",
      "+-------+-----+\n",
      "|   live|   15|\n",
      "|   dead|   77|\n",
      "+-------+-----+\n",
      "\n",
      "0.7733990147783252"
     ]
    }
   ],
   "source": [
    "val gbt = pipelineGBT.fit(trainingData)\n",
    "gbt.save(\"GradientBoostingTreeModel\")\n",
    "val predictionsgbt = gbt.transform(testData)\n",
    "var gbtCorrect=correctPredictions(predictionsgbt)\n",
    "var gbtWrong=wrongPredictions(predictionsgbt)\n",
    "gbtWrong.show()\n",
    "val (gbtAccuracy,matrixGBT)= accuracy(gbtCorrect,gbtWrong,testData)\n",
    "accuracyString += \"GradientBoostingTree : \" + gbtAccuracy + \"\\n\"\n",
    "val confMatrixGBT = sc.parallelize(Seq(matrixGBT))\n",
    "confMatrixGBT.saveAsTextFile(\"GBTConfusion\")\n",
    "print(gbtAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decisiontreeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|outcome|Correct|\n",
      "+-------+-------+\n",
      "|   live|    282|\n",
      "|   dead|     32|\n",
      "+-------+-------+\n",
      "\n",
      "+-------+-----+\n",
      "|outcome|Error|\n",
      "+-------+-----+\n",
      "|   live|   15|\n",
      "|   dead|   77|\n",
      "+-------+-----+\n",
      "\n",
      "0.7733990147783252"
     ]
    }
   ],
   "source": [
    "val decisionTree = pipelinedecisionTree.fit(trainingData)\n",
    "decisionTree.save(\"DecisionTreeModel\")\n",
    "val predictionsdecisionTree = decisionTree.transform(testData)\n",
    "var decisionTreeCorrect=correctPredictions(predictionsgbt)\n",
    "var decisionTreeWrong=wrongPredictions(predictionsgbt)\n",
    "decisionTreeWrong.show()\n",
    "val (decisionTreeAccuracy,matrixDecisionTree) = accuracy(decisionTreeCorrect,decisionTreeWrong,testData)\n",
    "accuracyString += \"DecisionTree : \" + decisionTreeAccuracy + \"\\n\"\n",
    "print(decisionTreeAccuracy)\n",
    "val confMatrixDT = sc.parallelize(Seq(matrixDecisionTree))\n",
    "confMatrixDT.saveAsTextFile(\"DecisionTreeConfusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " var accuracyCompare = sc.parallelize(Seq(accuracyString))\n",
    " accuracyCompare.saveAsTextFile(\"CompareAccuracies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA ANALYSIS AGE WISE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3569"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array(35.0, 40.0, 45.0, 50.0, 55.0, 60.0, 65.0, Infinity)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.Bucketizer\n",
    "import org.apache.spark.sql.functions._\n",
    "import scala.collection.mutable.ArrayBuffer\n",
    "import org.apache.spark.sql.functions.{desc, asc}\n",
    "import org.apache.spark.ml.feature.SQLTransformer\n",
    "\n",
    "val minAge= mifemDataset.agg(min(\"age\")).first.getInt(0)\n",
    "print(minAge)\n",
    "var ArraySplits= ArrayBuffer[Double]()\n",
    "val maxAge= mifemDataset.agg(max(\"age\")).first.getInt(0)\n",
    "print(maxAge)\n",
    "for( i<-minAge to maxAge  by 5)\n",
    "{\n",
    "    ArraySplits.append(i)  \n",
    "   \n",
    "}\n",
    "ArraySplits.append(Double.PositiveInfinity)\n",
    "ArraySplits.toArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+-------+\n",
      "|age|AgeBucketed|outcome|\n",
      "+---+-----------+-------+\n",
      "| 69|        6.0|   live|\n",
      "| 69|        6.0|   dead|\n",
      "| 69|        6.0|   live|\n",
      "| 69|        6.0|   dead|\n",
      "| 69|        6.0|   live|\n",
      "| 69|        6.0|   live|\n",
      "| 69|        6.0|   dead|\n",
      "| 69|        6.0|   live|\n",
      "| 69|        6.0|   live|\n",
      "| 69|        6.0|   live|\n",
      "| 69|        6.0|   live|\n",
      "| 69|        6.0|   live|\n",
      "| 69|        6.0|   dead|\n",
      "| 69|        6.0|   live|\n",
      "| 69|        6.0|   live|\n",
      "| 69|        6.0|   live|\n",
      "| 69|        6.0|   live|\n",
      "| 69|        6.0|   dead|\n",
      "| 69|        6.0|   live|\n",
      "| 69|        6.0|   live|\n",
      "+---+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---+-----------+-------+\n",
      "|age|AgeBucketed|outcome|\n",
      "+---+-----------+-------+\n",
      "| 63|        5.0|   live|\n",
      "| 55|        4.0|   live|\n",
      "| 68|        6.0|   live|\n",
      "| 64|        5.0|   live|\n",
      "| 67|        6.0|   dead|\n",
      "| 66|        6.0|   live|\n",
      "| 63|        5.0|   live|\n",
      "| 68|        6.0|   dead|\n",
      "| 46|        2.0|   dead|\n",
      "| 66|        6.0|   dead|\n",
      "| 59|        4.0|   dead|\n",
      "| 63|        5.0|   live|\n",
      "| 55|        4.0|   live|\n",
      "| 56|        4.0|   live|\n",
      "| 67|        6.0|   dead|\n",
      "| 64|        5.0|   live|\n",
      "| 60|        5.0|   dead|\n",
      "| 61|        5.0|   dead|\n",
      "| 69|        6.0|   live|\n",
      "| 59|        4.0|   live|\n",
      "+---+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+------------+\n",
      "|AgeBucketed|TotalFemales|\n",
      "+-----------+------------+\n",
      "|        0.0|          16|\n",
      "|        1.0|          32|\n",
      "|        2.0|          60|\n",
      "|        3.0|         107|\n",
      "|        4.0|         214|\n",
      "|        5.0|         371|\n",
      "|        6.0|         495|\n",
      "+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val AgeBucketize = new Bucketizer().setInputCol(\"age\").setOutputCol(\"AgeBucketed\").setSplits(ArraySplits.toArray)\n",
    "AgeBucketize.transform(mifemDataset).select(\"age\",\"AgeBucketed\" ,\"outcome\").orderBy(desc(\"age\") ).orderBy(desc(\"AgeBucketed\") ).show()\n",
    "val AgeBucketsGroups =AgeBucketize.transform(mifemDataset).select(\"age\",\"AgeBucketed\" ,\"outcome\")\n",
    "AgeBucketsGroups.show\n",
    "AgeBucketsGroups.registerTempTable(\"AgeBucketsGroupsTable\")\n",
    "val totalfemales = AgeBucketsGroups.groupBy(\"AgeBucketed\").agg(count(\"*\") as \"TotalFemales\")\n",
    "totalfemales.sort(\"AgeBucketed\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+--------+-----------------+\n",
      "|AgeBucketed|TotalFemales|Survived|         Survial%|\n",
      "+-----------+------------+--------+-----------------+\n",
      "|        0.0|          16|      14|             87.5|\n",
      "|        1.0|          32|      29|           90.625|\n",
      "|        2.0|          60|      46|76.66666666666667|\n",
      "|        3.0|         107|      93|86.91588785046729|\n",
      "|        4.0|         214|     178|83.17757009345794|\n",
      "|        5.0|         371|     266|71.69811320754717|\n",
      "|        6.0|         495|     348| 70.3030303030303|\n",
      "+-----------+------------+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val Survivors = AgeBucketsGroups.where(col(\"outcome\") === \"live\").groupBy(\"AgeBucketed\").agg(count(\"*\") as \"Survived\")\n",
    "val SurvivedTable = totalfemales.join(Survivors,Seq(\"AgeBucketed\"),\"left_outer\")\n",
    "val survivalPercent = new SQLTransformer().setStatement(\"SELECT *,`survived`/`totalfemales` *100 as `Survial%` FROM __THIS__ order by AgeBucketed\")\n",
    "val AgeGroupWisePercent = survivalPercent.transform(SurvivedTable)\n",
    "AgeGroupWisePercent.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
